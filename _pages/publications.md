---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

### Book Chapters

* [Adversarial Learning and Secure AI](https://www.cambridge.org/highereducation/books/adversarial-learning-and-secure-ai/79986B5D288511757C2A95D71262E039#overview)<br>
  David J. Miller, **Zhen Xiang**, George Kesidis<br>
  Cambridge University Press, 2023.

### Conference Papers

* [Improved activation clipping for universal backdoor mitigation and test-time detection](https://ieeexplore.ieee.org/abstract/document/10734765)<br>
  Hang Wang, **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Workshop on Machine Learning for Signal Processing (**MLSP**), 2024.

* [ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs](https://openreview.net/pdf?id=c93SBwz1Ma)<br>
  Fengqing Jiang, Zhangchen Xu, Luyao Niu, **Zhen Xiang**, Bhaskar Ramasubramanian, Bo Li, Radha Poovendran<br>
  The Association for Computational Linguistics (**ACL**), 2024.

* [BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models](https://openreview.net/pdf?id=c93SBwz1Ma)<br>
  **Zhen Xiang**, Fengqing Jiang, Zidi Xiong, Bhaskar Ramasubramanian, Radha Poovendran, Bo Li<br>
  International Conference on Learning Representations (**ICLR**), 2024.

* [MMBD: Post-Training Detection of Backdoor Attacks with Arbitrary Backdoor Pattern Types Using a Maximum Margin Statistic](https://arxiv.org/abs/2205.06900)<br>
  Hang Wang, **Zhen Xiang** (co-first author), David J. Miller, George Kesidis<br>
  IEEE Symposium on Security and Privacy (**S&P**), 2024.

* [CBD: A Certified Backdoor Detector Based on Local Dominant Probability](https://arxiv.org/abs/2310.17498)<br>
  **Zhen Xiang**, Zidi Xiong, Bo Li<br>
  Advances in Neural Information Processing Systems (**NeurIPS**), 2023.

* [UMD: Unsupervised Model Detection for X2X Backdoor Attacks](https://openreview.net/forum?id=t0ozPUGnBs)<br>
  **Zhen Xiang**, Zidi Xiong, Bo Li<br>
  IEEE International Conference on Machine Learning (**ICML**), 2023.

* A BIC-based Mixture Model Defense against Data Poisoning Attacks on Classifiers<br>
  Xi Li, **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Workshop on Machine Learning for Signal Processing (**MLSP**), 2023.

* [Training Set Cleansing of Backdoor Poisoning by Self-Supervised Representation Learning](https://ieeexplore.ieee.org/document/10097244/authors#authors)<br>
  Hang Wang, Sahar Karami, Ousmane Dia, Hippolyt Ritter, Ehsan Emamjomeh-Zadeh, Jiahui Chen, **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2023.

* [Test-Time Detection of Backdoor Triggers for Poisoned Deep Neural Networks](https://ieeexplore.ieee.org/abstract/document/9746573)<br>
  Xi Li, **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022.
  
* [Detecting Backdoor Attacks Against Point Cloud Classifiers](https://ieeexplore.ieee.org/abstract/document/9747194)<br>
  **Zhen Xiang**, David J. Miller, Siheng Chen, Xi Li, George Kesidis<br>
  IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2022.

* [Post-Training Detection of Backdoor Attacks for Two-Class and Multi-Attack Scenarios](https://arxiv.org/pdf/2201.08474.pdf)<br>
  **Zhen Xiang**, David J. Miller, George Kesidis<br>
  International Conference on Learning Representations (**ICLR**), 2022.

* [L-red: Efficient post-training detection of imperceptible backdoor attacks without access to the training set](https://arxiv.org/pdf/2010.09987.pdf)<br>
  **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2021.

* [A Backdoor Attack against 3D Point Cloud Classifiers](https://openaccess.thecvf.com/content/ICCV2021/papers/Xiang_A_Backdoor_Attack_Against_3D_Point_Cloud_Classifiers_ICCV_2021_paper.pdf)<br>
  **Zhen Xiang**, David J. Miller, Siheng Chen, Xi Li, George Kesidis<br>
  International Conference on Computer Vision (**ICCV**), 2021.
  
* [A Scalable Mixture Model Based Defense against Data Poisoning Attacks on Classifiers](https://link.springer.com/chapter/10.1007/978-3-030-61725-7_31)<br>
  Xi Li, David J. Miller, **Zhen Xiang**, George Kesidis<br>
  International Conference on Dynamic Data Driven Application Systems (**DDDAS**), 2020.

* [Revealing Perceptible Backdoors in DNNs, without the Training Set, via the Maximum Achievable Misclassification Fraction Statistic](https://ieeexplore.ieee.org/abstract/document/9231861)<br>
  **Zhen Xiang**, David J. Miller, Hang Wang, George Kesidis<br>
  IEEE International Workshop on Machine Learning for Signal Processing (**MLSP**), 2020.

* [Revealing backdoors, post-training, in DNN classifiers via novel inference on optimized perturbations inducing group misclassification](https://ieeexplore.ieee.org/abstract/document/9054581)<br>
  **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Conference on Acoustics, Speech and Signal Processing (**ICASSP**), 2020.

* [A Benchmark Study of Backdoor Data Poisoning Defenses for Deep Neural Network Classifiers and a Novel Defense](https://ieeexplore.ieee.org/abstract/document/8918908)<br>
  **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE International Workshop on Machine Learning for Signal Processing (**MLSP**), 2019.
  
* [Locally Optimal, Delay-Tolerant Predictive Source Coding](https://ieeexplore.ieee.org/abstract/document/8362243)<br>
  **Zhen Xiang**, David J. Miller<br>
  52nd Annual Conference on Information Sciences and Systems (**CISS**), 2018.


### Journal Papers

* [Correcting the distribution of batch normalization signals for Trojan mitigation](https://www.sciencedirect.com/science/article/pii/S0925231224015236)<br>
  Xi Li, **Zhen Xiang** (co-first author), David J. Miller, George Kesidis<br>
  Neurocomputing, 2024.

* BIC-based Mixture Model Defense against Data Poisoning Attacks on Classifiers: A Comprehensive Study<br>
  Xi Li, David J. Miller, **Zhen Xiang**, George Kesidis<br>
  IEEE Transactions on Knowledge and Data Engineering (**TKDE**), 2024.

* [Reverse Engineering Imperceptible Backdoor Attacks on Deep Neural Networks for Detection and Training Set Cleansing](https://www.sciencedirect.com/science/article/pii/S0167404821001048)<br>
  **Zhen Xiang**, David J. Miller, George Kesidis<br>
  Computers & Security, 2021.
  
* [Detecting Scene-Plausible Perceptible Backdoors in Trained DNNs Without Access to the Training Set](https://direct.mit.edu/neco/article-abstract/33/5/1329/97494/Detecting-Scene-Plausible-Perceptible-Backdoors-in)<br>
  **Zhen Xiang**, David J. Miller, Hang Wang, George Kesidis<br>
  Neural Computation, 2021.

* [Detection of Backdoors in Trained Classifiers Without Access to the Training Set](https://ieeexplore.ieee.org/abstract/document/9296553)<br>
  **Zhen Xiang**, David J. Miller, George Kesidis<br>
  IEEE Transactions on Neural Networks and Learning Systems (**TNNLS**), 2020.

* [Adversarial Learning Targeting Deep Neural Network Classification: A Comprehensive Review of Defenses Against Attacks](https://ieeexplore.ieee.org/abstract/document/9013065)<br>
  David J. Miller, **Zhen Xiang**, George Kesidis<br>
  Proceedings of the IEEE, 2020.
  
